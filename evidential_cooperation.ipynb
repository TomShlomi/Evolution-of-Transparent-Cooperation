{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import cProfile\n",
    "import pstats\n",
    "\n",
    "from parameter_functions import distance_mse, distance_null, distance_discrete, get_prisoners_dilemma, get_stag_hunt, get_uniform_game, get_normal_game, Net\n",
    "from evidential_cooperation import Agent, Environment, get_average_scores\n",
    "from agent_generation import generate_twins, diverging_twins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get average scores over multiple runs with agents trained on evidential cooperation\n",
    "distance_f, distance_f_name = distance_mse, 'MSE'\n",
    "game_generator, game_generator_name = get_prisoners_dilemma, 'PD'\n",
    "agents_generator, agents_generator_name = diverging_twins, 'DIVERGING'\n",
    "num_rounds, num_games, num_trials = 3000, 1, 1 # runtime is proportional to num_rounds * num_games * num_trials\n",
    "death_rate = 0.0\n",
    "net_n, agents_per_net = 2, 2 # number agents = net_n * agents_per_net\n",
    "random_inputs = 0\n",
    "lr = 0.001\n",
    "\n",
    "average_scores, nets = None, None\n",
    "cProfile.run('average_scores, nets = get_average_scores(agents_generator=lambda: agents_generator(distance_f=distance_f, net_n=net_n, agents_per_net=agents_per_net, random_inputs=random_inputs, lr=lr), game_generator=game_generator, death_rate=death_rate, num_trials=num_trials, num_rounds=num_rounds, num_games=num_games, random_inputs=random_inputs, verbose=True)', 'stats/stats {}nets {}agents {} {} {} {}rounds {}games {}death {}trials'.format(net_n, net_n*agents_per_net, game_generator_name, distance_f_name, agents_generator_name, num_rounds, num_games, death_rate, num_trials))\n",
    "\n",
    "# Plot and save the average scores\n",
    "plt.clf()\n",
    "plt.plot(average_scores)\n",
    "plt.savefig('graphs/{}nets {}agents {} {} {} {}rounds {}games {}death {}trials.png'.format(net_n, net_n*agents_per_net, game_generator_name, distance_f_name, agents_generator_name, num_rounds, num_games, death_rate, num_trials))\n",
    "plt.show()\n",
    "with open('graphs/{}nets {}agents {} {} {} {}rounds {}games {}death {}trials.csv'.format(net_n, net_n*agents_per_net, game_generator_name, distance_f_name, agents_generator_name, num_rounds, num_games, death_rate, num_trials), 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(average_scores)\n",
    "\n",
    "# Save the trained networks\n",
    "for i, net in enumerate(nets):\n",
    "    torch.save(net.state_dict(), 'models/net{} {}nets {}agents {} {} {} {}rounds {}games {}death {}trials'.format(i, net_n, net_n*agents_per_net, game_generator_name, distance_f_name, agents_generator_name, num_rounds, num_games, death_rate, num_trials))\n",
    "\n",
    "print('Average score: {}'.format(sum(average_scores)/num_rounds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_f, distance_f_name = distance_mse, 'MSE'\n",
    "game_generator, game_generator_name = get_prisoners_dilemma, 'PD'\n",
    "num_rounds, num_games, death_rate, num_trials = 1000, 1, 0.0, 100\n",
    "net_n = 2\n",
    "agents_per_net = 2\n",
    "\n",
    "nets = [Net(hidden_size=16) for _ in range(net_n)]\n",
    "[net.load_state_dict(torch.load('models/net{}|{} {} {} {}rounds {}games {}death.pt'.format(i+1, net_n, game_generator_name, distance_f_name, num_rounds, num_games, death_rate))) for i, net in enumerate(nets)]\n",
    "\n",
    "\n",
    "print(\"Auto-cooperation: \", end='')\n",
    "for net in nets:\n",
    "    print(net(torch.cat((get_prisoners_dilemma().flatten(), torch.tensor([0])))), end=' ')\n",
    "print(\"\\nCooperation: \", end='')\n",
    "for net in nets:\n",
    "    print(net(torch.cat((get_prisoners_dilemma().flatten(), torch.tensor([distance_mse(nets[0], nets[1])])))), end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pstats.Stats('stats/stats 2nets 4agents PD MSE DIVERGING 3000rounds 1games 0.0death 1trials')\n",
    "p.strip_dirs().sort_stats('cumulative').print_stats()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
